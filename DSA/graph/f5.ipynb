{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd053b144c10255056ba138318079d6915f61635f604f049884bb1cb292c1bb44d7",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Betweenness Centrality (Centrality Measure)\n",
    "# Difficulty Level : Expert\n",
    "# Last Updated : 10 Feb, 2018\n",
    "# In graph theory, betweenness centrality is a measure of centrality in a graph based on shortest paths. For every pair of vertices in a connected graph, there exists at least one shortest path between the vertices such that either the number of edges that the path passes through (for unweighted graphs) or the sum of the weights of the edges (for weighted graphs) is minimized. The betweenness centrality for each vertex is the number of these shortest paths that pass through the vertex.\n",
    "\n",
    "# Betweenness centrality finds wide application in network theory: it represents the degree of which nodes stand between each other. For example, in a telecommunications network, a node with higher betweenness centrality would have more control over the network, because more information will pass through that node. Betweenness centrality was devised as a general measure of centrality: it applies to a wide range of problems in network theory, including problems related to social networks, biology, transport and scientific cooperation.\n",
    "\n",
    "# Definition\n",
    "\n",
    "# The betweenness centrality of a node {\\displaystyle v} v is given by the expression:\n",
    "\n",
    "#  g(v)=\\sum _{{s\\neq v\\neq t}}{\\frac  {\\sigma _{{st}}(v)}{\\sigma _{{st}}}}\n",
    "\n",
    "\n",
    "\n",
    "# where \\sigma_{st} is the total number of shortest paths from node s to node  t and  \\sigma_{st}(v) is the number of those paths that pass through  v.\n",
    "\n",
    "# Note that the betweenness centrality of a node scales with the number of pairs of nodes as implied by the summation indices. Therefore, the calculation may be rescaled by dividing through by the number of pairs of nodes not including  v, so that g\\in [0,1]. The division is done by  (N-1)(N-2) for directed graphs and  (N-1)(N-2)/2 for undirected graphs, where  N is the number of nodes in the giant component. Note that this scales for the highest possible value, where one node is crossed by every single shortest path. This is often not the case, and a normalization can be performed without a loss of precision\n",
    "\n",
    "# {\\mbox{normal}}(g(v))={\\frac  {g(v)-\\min(g)}{\\max(g)-\\min(g)}}\n",
    "# which results in:\n",
    "\n",
    "#  \\max(normal)=1\n",
    "#  \\min(normal)=0\n",
    "# Note that this will always be a scaling from a smaller range into a larger range, so no precision is lost.\n",
    "\n",
    "# Weighted Networks\n",
    "# In a weighted network the links connecting the nodes are no longer treated as binary interactions, but are weighted in proportion to their capacity, influence, frequency, etc., which adds another dimension of heterogeneity within the network beyond the topological effects. A nodeâ€™s strength in a weighted network is given by the sum of the weights of its adjacent edges.\n",
    "\n",
    "#  s_{{i}}=\\sum _{{j=1}}^{{N}}a_{{ij}}w_{{ij}}\n",
    "# With a_{ij} and  w_{ij} being adjacency and weight matrices between nodes  i and  j, respectively. Analogous to the power law distribution of degree found in scale free networks, the strength of a given node follows a power law distribution as well.\n",
    "\n",
    "#  s(k)\\approx k^{\\beta }\n",
    "# A study of the average value  s(b) of the strength for vertices with betweenness  b shows that the functional behavior can be approximated by a scaling form\n",
    "\n",
    "#  s(b)\\approx b^{{\\alpha }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def betweenness_centrality(G, k=None, normalized=True, weight=None,\n",
    "\t\t\t\t\t\tendpoints=False, seed=None):\n",
    "\tr\"\"\"Compute the shortest-path betweenness centrality for nodes.\n",
    "\n",
    "\tBetweenness centrality of a node $v$ is the sum of the\n",
    "\tfraction of all-pairs shortest paths that pass through $v$\n",
    "\n",
    "\t.. math::\n",
    "\n",
    "\tc_B(v) =\\sum_{s,t \\in V} \\frac{\\sigma(s, t|v)}{\\sigma(s, t)}\n",
    "\n",
    "\twhere $V$ is the set of nodes, $\\sigma(s, t)$ is the number of\n",
    "\tshortest $(s, t)$-paths, and $\\sigma(s, t|v)$ is the number of\n",
    "\tthose paths passing through some node $v$ other than $s, t$.\n",
    "\tIf $s = t$, $\\sigma(s, t) = 1$, and if $v \\in {s, t}$,\n",
    "\t$\\sigma(s, t|v) = 0$ [2]_.\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tG : graph\n",
    "\tA NetworkX graph.\n",
    "\n",
    "\tk : int, optional (default=None)\n",
    "\tIf k is not None use k node samples to estimate betweenness.\n",
    "\tThe value of k <= n where n is the number of nodes in the graph.\n",
    "\tHigher values give better approximation.\n",
    "\n",
    "\tnormalized : bool, optional\n",
    "\tIf True the betweenness values are normalized by `2/((n-1)(n-2))`\n",
    "\tfor graphs, and `1/((n-1)(n-2))` for directed graphs where `n`\n",
    "\tis the number of nodes in G.\n",
    "\n",
    "\tweight : None or string, optional (default=None)\n",
    "\tIf None, all edge weights are considered equal.\n",
    "\tOtherwise holds the name of the edge attribute used as weight.\n",
    "\n",
    "\tendpoints : bool, optional\n",
    "\tIf True include the endpoints in the shortest path counts.\n",
    "\n",
    "\tReturns\n",
    "\t-------\n",
    "\tnodes : dictionary\n",
    "\tDictionary of nodes with betweenness centrality as the value.\n",
    "\n",
    "\t\n",
    "\tNotes\n",
    "\t-----\n",
    "\tThe algorithm is from Ulrik Brandes [1]_.\n",
    "\tSee [4]_ for the original first published version and [2]_ for details on\n",
    "\talgorithms for variations and related metrics.\n",
    "\n",
    "\tFor approximate betweenness calculations set k=#samples to use\n",
    "\tk nodes (\"pivots\") to estimate the betweenness values. For an estimate\n",
    "\tof the number of pivots needed see [3]_.\n",
    "\n",
    "\tFor weighted graphs the edge weights must be greater than zero.\n",
    "\tZero edge weights can produce an infinite number of equal length\n",
    "\tpaths between pairs of nodes.\n",
    "\n",
    "\t\n",
    "\t\"\"\"\n",
    "\tbetweenness = dict.fromkeys(G, 0.0) # b[v]=0 for v in G\n",
    "\tif k is None:\n",
    "\t\tnodes = G\n",
    "\telse:\n",
    "\t\trandom.seed(seed)\n",
    "\t\tnodes = random.sample(G.nodes(), k)\n",
    "\tfor s in nodes:\n",
    "\n",
    "\t\t# single source shortest paths\n",
    "\t\tif weight is None: # use BFS\n",
    "\t\t\tS, P, sigma = _single_source_shortest_path_basic(G, s)\n",
    "\t\telse: # use Dijkstra's algorithm\n",
    "\t\t\tS, P, sigma = _single_source_dijkstra_path_basic(G, s, weight)\n",
    "\n",
    "\t\t# accumulation\n",
    "\t\tif endpoints:\n",
    "\t\t\tbetweenness = _accumulate_endpoints(betweenness, S, P, sigma, s)\n",
    "\t\telse:\n",
    "\t\t\tbetweenness = _accumulate_basic(betweenness, S, P, sigma, s)\n",
    "\n",
    "\t# rescaling\n",
    "\tbetweenness = _rescale(betweenness, len(G), normalized=normalized,\n",
    "\t\t\t\t\t\tdirected=G.is_directed(), k=k)\n",
    "\treturn betweenness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{0: 0.01077071215876738, 1: 0.01279537178396722, 2: 0.010238366561520822, 3: 0.008702083966564758, 4: 0.017912393252397674, 5: 0.013155027366205262, 6: 0.013304707964940479, 7: 0.0064817921285508315, 8: 0.0076240978270540076, 9: 0.014298916300341871, 10: 0.010796289512644473, 11: 0.009940201383028514, 12: 0.008769812764272392, 13: 0.01067112811935741, 14: 0.018471577201812715, 15: 0.011644070349921112, 16: 0.007394694803276656, 17: 0.00872773731654126, 18: 0.015783852511537005, 19: 0.012925086854033433, 20: 0.012366213602826668, 21: 0.007569292961443244, 22: 0.010470074139160193, 23: 0.010109610620308324, 24: 0.008163427325203879, 25: 0.010199704914827808, 26: 0.012671587792129428, 27: 0.018903990306301233, 28: 0.006004575628675267, 29: 0.006246065414732881, 30: 0.022789071279585908, 31: 0.012134481646529884, 32: 0.0137093299369394, 33: 0.01030523533761671, 34: 0.008838055562995537, 35: 0.005701158025706265, 36: 0.009781210376316837, 37: 0.010090403386965431, 38: 0.0067162109971668, 39: 0.012997815362247978, 40: 0.016617247409564335, 41: 0.005852491818128072, 42: 0.005773101971449731, 43: 0.01360856771507874, 44: 0.010261182080896809, 45: 0.010662718300773522, 46: 0.011432117228679272, 47: 0.0067480227561694354, 48: 0.00947888531270568, 49: 0.011859618417241466}\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "g=nx.erdos_renyi_graph(50,0.5)\n",
    "b=nx.betweenness_centrality(g)\n",
    "print(b)"
   ]
  }
 ]
}